{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this algorithm we input color images and classify our images into ten classes. These classes represent airplanes,cars,birds,cats,deer,dogs,frogs, horses , ships and trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.datasets.cifar10' from 'C:\\\\Users\\\\My HP Pavilion\\\\Anaconda3\\\\New folder\\\\envs\\\\py-TF\\\\lib\\\\site-packages\\\\keras\\\\datasets\\\\cifar10.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_train, dtype ='float32')\n",
    "Y_train = np.array(y_train, dtype ='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test, dtype ='float32')\n",
    "Y_test = np.array(y_test, dtype ='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /=255\n",
    "X_test /=255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into validation and training dataset(No need to split into training and testing set because that is already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_validation , Y_train , Y_validation = train_test_split(X_train, Y_train, test_size=0.1, random_state =11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries for building the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=512)`\n",
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, 3, input_shape =(32, 32, 3),activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 3, 3, activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3,activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, 3, activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim = 512, activation ='relu'))\n",
    "model.add(Dense(output_dim = 10, activation ='sigmoid'))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting our model on training data for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My HP Pavilion\\Anaconda3\\New folder\\envs\\py-TF\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 1989s 44ms/step - loss: 1.7592 - acc: 0.3470 - val_loss: 1.8096 - val_acc: 0.3986\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 2160s 48ms/step - loss: 1.0982 - acc: 0.6139 - val_loss: 1.0020 - val_acc: 0.6480\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 1198s 27ms/step - loss: 0.8942 - acc: 0.6854 - val_loss: 0.8797 - val_acc: 0.6874\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 1182s 26ms/step - loss: 0.7853 - acc: 0.7258 - val_loss: 0.9932 - val_acc: 0.6710\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 1178s 26ms/step - loss: 0.7119 - acc: 0.7503 - val_loss: 0.7426 - val_acc: 0.7440\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 1139s 25ms/step - loss: 0.6548 - acc: 0.7706 - val_loss: 0.7382 - val_acc: 0.7422\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 1126s 25ms/step - loss: 0.6042 - acc: 0.7877 - val_loss: 0.7438 - val_acc: 0.7422\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 1128s 25ms/step - loss: 0.5626 - acc: 0.8017 - val_loss: 0.9941 - val_acc: 0.6960\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 1128s 25ms/step - loss: 0.5211 - acc: 0.8160 - val_loss: 0.6767 - val_acc: 0.7748\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 1134s 25ms/step - loss: 0.4803 - acc: 0.8320 - val_loss: 0.7385 - val_acc: 0.7572\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 1127s 25ms/step - loss: 0.4508 - acc: 0.8414 - val_loss: 0.7359 - val_acc: 0.7622\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 1120s 25ms/step - loss: 0.4244 - acc: 0.8487 - val_loss: 0.6785 - val_acc: 0.7864\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 1119s 25ms/step - loss: 0.3977 - acc: 0.8594 - val_loss: 0.6410 - val_acc: 0.7910\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 1106s 25ms/step - loss: 0.3745 - acc: 0.8695 - val_loss: 0.7241 - val_acc: 0.7778\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 1080s 24ms/step - loss: 0.3529 - acc: 0.8754 - val_loss: 0.7214 - val_acc: 0.7778\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 1081s 24ms/step - loss: 0.3274 - acc: 0.8843 - val_loss: 0.6626 - val_acc: 0.7946\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 5299s 118ms/step - loss: 0.3117 - acc: 0.8904 - val_loss: 0.7097 - val_acc: 0.7818\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 1077s 24ms/step - loss: 0.2995 - acc: 0.8954 - val_loss: 0.7394 - val_acc: 0.7798\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 2429s 54ms/step - loss: 0.2834 - acc: 0.8999 - val_loss: 0.7306 - val_acc: 0.7840\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 1078s 24ms/step - loss: 0.2763 - acc: 0.9042 - val_loss: 0.7498 - val_acc: 0.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x31c149e828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "             Y_train,\n",
    "             batch_size = 32,\n",
    "             nb_epoch = epochs,\n",
    "             verbose = 1,\n",
    "             validation_data = (X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above training is done,we find that our training accuracy turns out to be 90.42% and validation accuracy is77.76%. Now we will test our model on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing classification report for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.84      0.77      0.81      1000\n",
      "     class 1       0.92      0.86      0.89      1000\n",
      "     class 2       0.80      0.61      0.69      1000\n",
      "     class 3       0.63      0.58      0.60      1000\n",
      "     class 4       0.71      0.82      0.76      1000\n",
      "     class 5       0.66      0.73      0.69      1000\n",
      "     class 6       0.79      0.89      0.84      1000\n",
      "     class 7       0.82      0.83      0.83      1000\n",
      "     class 8       0.92      0.80      0.86      1000\n",
      "     class 9       0.78      0.93      0.85      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.79      0.78      0.78     10000\n",
      "weighted avg       0.79      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_classes=10\n",
    "target_names =[\"class {}\".format(i) for i in range(num_classes)]\n",
    "\n",
    "print(classification_report(Y_test, predicted_classes, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
